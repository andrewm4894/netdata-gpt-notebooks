{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chart Descriptions"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/andrewm4894/netdata-gpt-notebooks/blob/main/notebooks/chart_descriptions/chart_descriptions.ipynb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if running in colab uncomment the following line and run it to install the required packages\n",
    "#!pip install python-dotenv netdata-pandas openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from netdata_pandas.data_cloud import get_data_cloud\n",
    "import openai\n",
    "import pprint as pp\n",
    "from urllib.parse import urlparse\n",
    "import requests\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# load tokens from .env file\n",
    "load_dotenv()\n",
    "\n",
    "NETDATA_API_TOKEN = os.getenv('NETDATA_API_TOKEN')\n",
    "OPENAI_API_KEY = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "openai.api_key = OPENAI_API_KEY"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "# inputs\n",
    "space_id = 'ea93d7b8-0df6-45c0-b13d-1560996c89eb' \n",
    "room_id = 'd8a4e0c5-7c79-4145-900e-83a9f06fcb6a'\n",
    "chart = None\n",
    "chart_startswith = 'prometheus.'\n",
    "output_dir = f'output/{chart_startswith}'\n",
    "now = datetime.now().strftime(\"%Y%m%d_%H%M%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_charts_cloud(space_id, room_id, api_token=None, base_url='https://app.netdata.cloud', node_ids=[]):\n",
    "    \"\"\"Get charts from netdata cloud api.\n",
    "    \"\"\"\n",
    "    \n",
    "    if api_token is None:\n",
    "        api_token = os.getenv('NETDATA_API_TOKEN')\n",
    "    \n",
    "    base_url = 'https://app.netdata.cloud'\n",
    "    url = f'{base_url}/api/v2/spaces/{space_id}/rooms/{room_id}/charts'\n",
    "    headers = {'Accept': '*/*', 'Content-Type': 'application/json', 'Authorization': f'Bearer {api_token}'}\n",
    "    data = {\n",
    "        'filter': {\n",
    "            'nodeIDs': node_ids,\n",
    "        }\n",
    "    }\n",
    "    r = requests.post(url, headers=headers, data=json.dumps(data))\n",
    "    \n",
    "    if r.status_code != 200:\n",
    "        \n",
    "        print(f'Error: {r.status_code, r.text}')\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "            \n",
    "        return r.json()['results']\n",
    "\n",
    "\n",
    "def make_prompt(chart, chart_json):\n",
    "    prompt = f\"\"\"\n",
    "    You are an experienced SRE and sysadmin.\n",
    "\n",
    "    You are monitoring your infrastructure using Netdata Cloud.\n",
    "\n",
    "    You are documenting individual charts and their dimensions to help other users.\n",
    "\n",
    "    The chart_json object is available to you and follows the format below:\n",
    "\n",
    "    ```json\n",
    "    {{\n",
    "        \"id\": \"the chart id\",\n",
    "        \"title\": \"the chart title\",\n",
    "        \"dimensions\": \"a list of the dimensions\",\n",
    "        \"units\": \"the units of the chart\",\n",
    "        \"family\": \"the menu family of the chart\",\n",
    "        \"context\": \"context of the chat. it follows structure like <type>.<name> where <type> also impacts where in the menu the chart appears and so can give hints of what it might relate to\",\n",
    "        \"chart_type\": \"usually line or stacked or area - this is the type of chart\",\n",
    "        \"chart_labels\": \"some optional labels or tags for the chart that cone also sometimes be useful to help understand the chart\",\n",
    "    }}\n",
    "    ```\n",
    "\n",
    "    Here is the individual chart_json object describing the `{chart}` chart you are documenting:\n",
    "\n",
    "    ```json\n",
    "    {chart_json}\n",
    "    ```\n",
    "\n",
    "    Can you write short, useful and educational description of the chart and its dimensions? \n",
    "\n",
    "    Please follow a json format like this (the output needs to be valid json):\n",
    "\n",
    "    ```json\n",
    "    {{\n",
    "        \"chart_id\": \"{chart}\",\n",
    "        \"chart_description\": \"<add description here>\",\n",
    "        \"dimension_descriptions\": [\n",
    "            {{\n",
    "                \"<dimension name>\": \"<add dimension description here>\",\n",
    "                ...\n",
    "            }}]\n",
    "    }}\n",
    "    ```\n",
    "    \"\"\"\n",
    "    \n",
    "    return prompt\n",
    "\n",
    "\n",
    "charts = get_charts_cloud(space_id, room_id, api_token=NETDATA_API_TOKEN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds_count\n",
      "['prometheus.aws-cluster-autoscaler.apiserver_audit_event_total', 'prometheus.aws-cluster-autoscaler.apiserver_audit_requests_rejected_total', 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds', 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds_count', 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds_sum', 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_failures_total', 'prometheus.aws-cluster-autoscaler.apiserver_storage_envelope_transformation_cache_misses_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_cluster_safe_to_autoscale', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_created_node_groups_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_deleted_node_groups_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_evicted_pods_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds_sum', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds_sum', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_last_activity', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_max_nodes_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_nap_enabled', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_node_groups_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_nodes_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_old_unregistered_nodes_removed_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scale_down_in_cooldown', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scaled_down_nodes_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scaled_up_nodes_total', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unneeded_nodes_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unremovable_nodes_count', 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unschedulable_pods_count', 'prometheus.aws-cluster-autoscaler.get_token_count', 'prometheus.aws-cluster-autoscaler.get_token_fail_count', 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds', 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds_count', 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds_sum', 'prometheus.aws-cluster-autoscaler.go_goroutines', 'prometheus.aws-cluster-autoscaler.go_memstats_alloc_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_alloc_bytes_total', 'prometheus.aws-cluster-autoscaler.go_memstats_buck_hash_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_frees_total', 'prometheus.aws-cluster-autoscaler.go_memstats_gc_cpu_fraction', 'prometheus.aws-cluster-autoscaler.go_memstats_gc_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_alloc_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_idle_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_inuse_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_objects', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_released_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_heap_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_last_gc_time_seconds', 'prometheus.aws-cluster-autoscaler.go_memstats_lookups_total', 'prometheus.aws-cluster-autoscaler.go_memstats_mallocs_total', 'prometheus.aws-cluster-autoscaler.go_memstats_mcache_inuse_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_mcache_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_mspan_inuse_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_mspan_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_next_gc_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_other_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_stack_inuse_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_stack_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_memstats_sys_bytes', 'prometheus.aws-cluster-autoscaler.go_threads', 'prometheus.aws-cluster-autoscaler.process_cpu_seconds_total', 'prometheus.aws-cluster-autoscaler.process_max_fds', 'prometheus.aws-cluster-autoscaler.process_open_fds', 'prometheus.aws-cluster-autoscaler.process_resident_memory_bytes', 'prometheus.aws-cluster-autoscaler.process_start_time_seconds', 'prometheus.aws-cluster-autoscaler.process_virtual_memory_bytes', 'prometheus.aws-cluster-autoscaler.process_virtual_memory_max_bytes', 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_certificate_rotation_age', 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_certificate_rotation_age_count', 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_certificate_rotation_age_sum', 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_ttl_seconds', 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds', 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds_count', 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds_sum', 'prometheus.aws-cluster-autoscaler.rest_client_requests_total', 'prometheus.aws-load-balancer-controller.controller_runtime_active_workers', 'prometheus.aws-load-balancer-controller.controller_runtime_max_concurrent_reconciles', 'prometheus.aws-load-balancer-controller.controller_runtime_reconcile_errors_total', 'prometheus.aws-load-balancer-controller.controller_runtime_reconcile_total', 'prometheus.aws-load-balancer-controller.controller_runtime_webhook_requests_in_flight', 'prometheus.aws-load-balancer-controller.controller_runtime_webhook_requests_total', 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds', 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds_count', 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds_sum', 'prometheus.aws-load-balancer-controller.go_goroutines', 'prometheus.aws-load-balancer-controller.go_memstats_alloc_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_alloc_bytes_total', 'prometheus.aws-load-balancer-controller.go_memstats_buck_hash_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_frees_total', 'prometheus.aws-load-balancer-controller.go_memstats_gc_cpu_fraction', 'prometheus.aws-load-balancer-controller.go_memstats_gc_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_heap_alloc_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_heap_idle_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_heap_inuse_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_heap_objects', 'prometheus.aws-load-balancer-controller.go_memstats_heap_released_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_heap_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_last_gc_time_seconds', 'prometheus.aws-load-balancer-controller.go_memstats_lookups_total', 'prometheus.aws-load-balancer-controller.go_memstats_mallocs_total', 'prometheus.aws-load-balancer-controller.go_memstats_mcache_inuse_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_mcache_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_mspan_inuse_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_mspan_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_next_gc_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_other_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_stack_inuse_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_stack_sys_bytes', 'prometheus.aws-load-balancer-controller.go_memstats_sys_bytes', 'prometheus.aws-load-balancer-controller.go_threads', 'prometheus.aws-load-balancer-controller.process_cpu_seconds_total', 'prometheus.aws-load-balancer-controller.process_max_fds', 'prometheus.aws-load-balancer-controller.process_open_fds', 'prometheus.aws-load-balancer-controller.process_resident_memory_bytes', 'prometheus.aws-load-balancer-controller.process_start_time_seconds', 'prometheus.aws-load-balancer-controller.process_virtual_memory_bytes', 'prometheus.aws-load-balancer-controller.process_virtual_memory_max_bytes', 'prometheus.aws-load-balancer-controller.rest_client_request_latency_seconds', 'prometheus.aws-load-balancer-controller.rest_client_request_latency_seconds_count', 'prometheus.aws-load-balancer-controller.rest_client_request_latency_seconds_sum', 'prometheus.aws-load-balancer-controller.rest_client_requests_total', 'prometheus.aws-load-balancer-controller.workqueue_adds_total', 'prometheus.aws-load-balancer-controller.workqueue_depth', 'prometheus.aws-load-balancer-controller.workqueue_longest_running_processor_seconds', 'prometheus.aws-load-balancer-controller.workqueue_queue_duration_seconds', 'prometheus.aws-load-balancer-controller.workqueue_queue_duration_seconds_count', 'prometheus.aws-load-balancer-controller.workqueue_queue_duration_seconds_sum', 'prometheus.aws-load-balancer-controller.workqueue_retries_total', 'prometheus.aws-load-balancer-controller.workqueue_unfinished_work_seconds', 'prometheus.aws-load-balancer-controller.workqueue_work_duration_seconds', 'prometheus.aws-load-balancer-controller.workqueue_work_duration_seconds_count', 'prometheus.aws-load-balancer-controller.workqueue_work_duration_seconds_sum', 'prometheus.velero.go_gc_duration_seconds', 'prometheus.velero.go_gc_duration_seconds_count', 'prometheus.velero.go_gc_duration_seconds_sum', 'prometheus.velero.go_goroutines', 'prometheus.velero.go_memstats_alloc_bytes', 'prometheus.velero.go_memstats_alloc_bytes_total', 'prometheus.velero.go_memstats_buck_hash_sys_bytes', 'prometheus.velero.go_memstats_frees_total', 'prometheus.velero.go_memstats_gc_cpu_fraction', 'prometheus.velero.go_memstats_gc_sys_bytes', 'prometheus.velero.go_memstats_heap_alloc_bytes', 'prometheus.velero.go_memstats_heap_idle_bytes', 'prometheus.velero.go_memstats_heap_inuse_bytes', 'prometheus.velero.go_memstats_heap_objects', 'prometheus.velero.go_memstats_heap_released_bytes', 'prometheus.velero.go_memstats_heap_sys_bytes', 'prometheus.velero.go_memstats_last_gc_time_seconds', 'prometheus.velero.go_memstats_lookups_total', 'prometheus.velero.go_memstats_mallocs_total', 'prometheus.velero.go_memstats_mcache_inuse_bytes', 'prometheus.velero.go_memstats_mcache_sys_bytes', 'prometheus.velero.go_memstats_mspan_inuse_bytes', 'prometheus.velero.go_memstats_mspan_sys_bytes', 'prometheus.velero.go_memstats_next_gc_bytes', 'prometheus.velero.go_memstats_other_sys_bytes', 'prometheus.velero.go_memstats_stack_inuse_bytes', 'prometheus.velero.go_memstats_stack_sys_bytes', 'prometheus.velero.go_memstats_sys_bytes', 'prometheus.velero.go_threads', 'prometheus.velero.process_cpu_seconds_total', 'prometheus.velero.process_max_fds', 'prometheus.velero.process_open_fds', 'prometheus.velero.process_resident_memory_bytes', 'prometheus.velero.process_start_time_seconds', 'prometheus.velero.process_virtual_memory_bytes', 'prometheus.velero.process_virtual_memory_max_bytes', 'prometheus.velero.promhttp_metric_handler_requests_in_flight', 'prometheus.velero.promhttp_metric_handler_requests_total', 'prometheus.velero.velero_backup_attempt_total', 'prometheus.velero.velero_backup_deletion_attempt_total', 'prometheus.velero.velero_backup_deletion_failure_total', 'prometheus.velero.velero_backup_deletion_success_total', 'prometheus.velero.velero_backup_duration_seconds', 'prometheus.velero.velero_backup_duration_seconds_count', 'prometheus.velero.velero_backup_duration_seconds_sum', 'prometheus.velero.velero_backup_failure_total', 'prometheus.velero.velero_backup_last_successful_timestamp', 'prometheus.velero.velero_backup_partial_failure_total', 'prometheus.velero.velero_backup_success_total', 'prometheus.velero.velero_backup_tarball_size_bytes', 'prometheus.velero.velero_backup_total', 'prometheus.velero.velero_backup_validation_failure_total', 'prometheus.velero.velero_restore_attempt_total', 'prometheus.velero.velero_restore_failed_total', 'prometheus.velero.velero_restore_partial_failure_total', 'prometheus.velero.velero_restore_success_total', 'prometheus.velero.velero_restore_total', 'prometheus.velero.velero_restore_validation_failed_total', 'prometheus.velero.velero_volume_snapshot_attempt_total', 'prometheus.velero.velero_volume_snapshot_failure_total', 'prometheus.velero.velero_volume_snapshot_success_total']\n"
     ]
    }
   ],
   "source": [
    "if chart == None:\n",
    "    charts_list = list(set(list(charts.keys())))\n",
    "    #charts_list = [c for c in charts_list if c.startswith('system.')]\n",
    "    #charts_list = [c for c in charts_list if 'prometheus.' not in c]\n",
    "    #charts_list = [c for c in charts_list if 'netdata.' not in c]\n",
    "    charts_list = [c for c in charts_list if c.startswith(chart_startswith)]\n",
    "    charts_list = sorted(charts_list)\n",
    "    chart = np.random.choice(charts_list)\n",
    "\n",
    "print(chart)\n",
    "print(charts_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_audit_event_total', 'chart_description': '[ALPHA] Counter of audit events generated and sent to the audit backend', 'dimension_descriptions': [{'apiserver_audit_event_total': 'The total number of audit events generated and sent to the audit backend per second.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_audit_requests_rejected_total', 'chart_description': 'This counter chart tracks the number of API server requests that have been rejected due to an error in the audit logging backend. The chart is in ALPHA stage and should be taken as a work in progress', 'dimension_descriptions': [{'apiserver_audit_requests_rejected_total': 'The total number of rejected requests per second due to an error in the audit logging backend'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds', 'chart_description': 'This chart measures the latencies in seconds of data encryption key (DEK) generation operations. It is in alpha and only for informational purposes.', 'dimension_descriptions': [{'bucket_+Inf': 'The number of observations that were unbounded (i.e., taking more time than any of the buckets measured).', 'bucket_0.000005': 'The number of observations that took 0.000005 seconds or less.', 'bucket_0.00001': 'The number of observations that took between 0.000005 and 0.00001 seconds.', 'bucket_0.00002': 'The number of observations that took between 0.00001 and 0.00002 seconds.', 'bucket_0.00004': 'The number of observations that took between 0.00002 and 0.00004 seconds.', 'bucket_0.00008': 'The number of observations that took between 0.00004 and 0.00008 seconds.', 'bucket_0.00016': 'The number of observations that took between 0.00008 and 0.00016 seconds.', 'bucket_0.00032': 'The number of observations that took between 0.00016 and 0.00032 seconds.', 'bucket_0.00064': 'The number of observations that took between 0.00032 and 0.00064 seconds.', 'bucket_0.00128': 'The number of observations that took between 0.00064 and 0.00128 seconds.', 'bucket_0.00256': 'The number of observations that took between 0.00128 and 0.00256 seconds.', 'bucket_0.00512': 'The number of observations that took between 0.00256 and 0.00512 seconds.', 'bucket_0.01024': 'The number of observations that took between 0.00512 and 0.01024 seconds.', 'bucket_0.02048': 'The number of observations that took between 0.01024 and 0.02048 seconds.', 'bucket_0.04096': 'The number of observations that took between 0.02048 and 0.04096 seconds.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds_count', 'chart_description': 'This chart represents the latencies in seconds of data encryption key generation operations in the apiserver storage of the AWS cluster autoscaler.', 'dimension_descriptions': [{'apiserver_storage_data_key_generation_duration_seconds_count': 'The time taken in seconds for generating an encryption key for the storage in the apiserver.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_duration_seconds_sum', 'chart_description': '[ALPHA] This chart shows the latencies in seconds of data encryption key (DEK) generation operations.', 'dimension_descriptions': [{'apiserver_storage_data_key_generation_duration_seconds_sum': 'The sum of time in seconds to generate a data encryption key (DEK) from the apiserver_storage.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_storage_data_key_generation_failures_total', 'chart_description': 'This chart provides the count of failed operations relating to the generation of data encryption keys (DEK) for API server storage from the Amazon Web Services (AWS) cluster autoscaler. A high value indicates issues with generating DEKs, likely resulting in impact to the performance of the autoscaler.', 'dimension_descriptions': [{'apiserver_storage_data_key_generation_failures_total': 'This dimension tracks the total number of failed operations related to generating data encryption keys (DEK) for API server storage. It provides insight into issues with DEK generation and their impact on the performance of the autoscaler.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.apiserver_storage_envelope_transformation_cache_misses_total', 'chart_description': 'This chart represents the total number of cache misses that occurred while accessing the key decryption key(KEK) for the apiserver storage envelope transformation.', 'dimension_descriptions': [{'apiserver_storage_envelope_transformation_cache_misses_total': 'The total number of cache misses that occurred while accessing the key decryption key(KEK) for the apiserver storage envelope transformation.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_cluster_safe_to_autoscale', 'chart_description': 'This chart shows whether or not the AWS cluster is healthy enough for autoscaling. It reports a 1 if it is safe to autoscale and 0 otherwise. This chart is currently in alpha stage.', 'dimension_descriptions': [{'cluster_autoscaler_cluster_safe_to_autoscale': \"Whether or not the cluster is healthy enough for autoscaling. A value of 1 indicates that the cluster is healthy enough for autoscaling, while a value of 0 indicates that it is not safe to autoscale. This dimension reports the current state of the cluster's health affecting the autoscaling operation.\"}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_created_node_groups_total', 'chart_description': 'This chart shows the number of node groups that were created by Node Autoprovisioning in AWS Cluster Autoscaler. It is an alpha feature and is subject to change.', 'dimension_descriptions': [{'cluster_autoscaler_created_node_groups_total': 'The total number of node groups created by Node Autoprovisioning in AWS Cluster Autoscaler.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_deleted_node_groups_total', 'chart_description': 'This chart shows the number of node groups deleted by Node Autoprovisioning in an AWS Cluster Autoscaler.', 'dimension_descriptions': [{'cluster_autoscaler_deleted_node_groups_total': 'The total number of node groups deleted by the Node Autoprovisioning process.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_evicted_pods_total', 'chart_description': 'This chart shows the number of pods evicted by Cluster Autoscaler (CA) in a particular AWS cluster. CA automatically adjusts the size of an AWS cluster by increasing or decreasing the number of nodes based on the demand. When a node is no longer needed, CA evicts the pods associated with it to save resources. This chart helps monitor the CA eviction process, which can affect the availability and performance of the services running in the cluster.', 'dimension_descriptions': [{'cluster_autoscaler_evicted_pods_total': 'The total number of pods evicted by CA over the chosen time period. This dimension can help identify trends in the CA eviction rate and determine whether the current cluster size is appropriate for the workload.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds', 'chart_description': 'This chart provides quantiles of timings for various parts of the Cluster Autoscaler (CA) main loop which helps to efficiently manage the nodes in a Kubernetes cluster. It provides an insight into how long it takes for different parts of the main loop to execute.', 'dimension_descriptions': [{'quantile_0.5': '50th percentile value of time taken by various parts of the CA main loop.', 'quantile_0.9': '90th percentile value of time taken by various parts of the CA main loop.', 'quantile_0.99': '99th percentile value of time taken by various parts of the CA main loop.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds_count', 'chart_description': 'This is an [ALPHA] chart that displays the quantiles of time taken by various components of the CA main loop in seconds. It is useful to monitor the efficiency and performance of the cluster autoscaler function in AWS.', 'dimension_descriptions': [{'cluster_autoscaler_function_duration_quantile_seconds_count': 'The time taken (in seconds) by various components of the CA main loop at specific time quantiles. This dimension can help identify components that may be taking too long to operate or contributing to poor performance.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_quantile_seconds_sum', 'chart_description': \"This chart displays the quantiles of time taken by various parts of the Cluster Autoscaler's main loop in seconds. The quantiles are calculated by Prometheus.\", 'dimension_descriptions': [{'cluster_autoscaler_function_duration_quantile_seconds_sum': 'The sum of time taken by the specified quantile of the main loop in seconds. This helps identify slow areas in the loop that may impact overall performance.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds', 'chart_description': 'This chart provides information on the time taken by various parts of CA (Cluster Autoscaler) main loop, which manages the size of Kubernetes clusters based on the demands of the workloads. The durations are broken down into various buckets (in seconds) to provide a distribution of how long each operation takes.', 'dimension_descriptions': [{'bucket_+Inf': 'This dimension represents the maximum time taken by an operation in seconds.', 'bucket_0.01': 'This dimension represents the time taken by an operation in 0.01s seconds.', 'bucket_0.05': 'This dimension represents the time taken by an operation in 0.05s seconds.', 'bucket_0.1': 'This dimension represents the time taken by an operation in 0.1s seconds.', 'bucket_0.5': 'This dimension represents the time taken by an operation in 0.5s seconds.', 'bucket_1': 'This dimension represents the time taken by an operation in 1s seconds.', 'bucket_10': 'This dimension represents the time taken by an operation in 10s seconds.', 'bucket_100': 'This dimension represents the time taken by an operation in 100s seconds.', 'bucket_1000': 'This dimension represents the time taken by an operation in 1000s seconds.', 'bucket_12.5': 'This dimension represents the time taken by an operation in 12.5s seconds.', 'bucket_15': 'This dimension represents the time taken by an operation in 15s seconds.', 'bucket_17.5': 'This dimension represents the time taken by an operation in 17.5s seconds.', 'bucket_2.5': 'This dimension represents the time taken by an operation in 2.5s seconds.', 'bucket_20': 'This dimension represents the time taken by an operation in 20s seconds.', 'bucket_22.5': 'This dimension represents the time taken by an operation in 22.5s seconds.', 'bucket_25': 'This dimension represents the time taken by an operation in 25s seconds.', 'bucket_27.5': 'This dimension represents the time taken by an operation in 27.5s seconds.', 'bucket_30': 'This dimension represents the time taken by an operation in 30s seconds.', 'bucket_5': 'This dimension represents the time taken by an operation in 5s seconds.', 'bucket_50': 'This dimension represents the time taken by an operation in 50s seconds.', 'bucket_7.5': 'This dimension represents the time taken by an operation in 7.5s seconds.', 'bucket_75': 'This dimension represents the time taken by an operation in 75s seconds.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds_count', 'chart_description': '[ALPHA] Time taken by various parts of CA main loop is a line chart that displays the duration of the various parts of the main loop for Cluster Autoscaler. It helps in understanding the time taken by different functions of Cluster Autoscaler and optimization of the cluster.', 'dimension_descriptions': [{'cluster_autoscaler_function_duration_seconds_count': 'The time taken by various parts of CA main loop is calculated for each second and is displayed on the y-axis of the chart. The x-axis represents time in seconds.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_function_duration_seconds_sum', 'chart_description': 'This chart shows the time taken by various parts of the Cluster Autoscaler (CA) main loop in seconds. The main loop is responsible for monitoring the resources in the cluster and scaling up or down the nodes in response to changes in resource demands.', 'dimension_descriptions': [{'cluster_autoscaler_function_duration_seconds_sum': 'The total time taken by the CA main loop. This includes the time spent on monitoring and scaling activities.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_last_activity', 'chart_description': 'This chart displays the last time the certain part of Cluster Autoscaler logic executed. It helps to monitor and analyze the activity of the Cluster Autoscaler.', 'dimension_descriptions': [{'cluster_autoscaler_last_activity': 'The timestamp of the last execution of a certain part of Cluster Autoscaler logic.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_max_nodes_count', 'chart_description': '[ALPHA] Maximum number of nodes in all node groups for autoscaling the cluster.', 'dimension_descriptions': [{'cluster_autoscaler_max_nodes_count': 'The maximum number of nodes that can be added to the cluster through autoscaling. This metric can help in understanding if the desired number of nodes are being added as per the autoscaling policy.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_nap_enabled', 'chart_description': \"This chart displays whether or not Node Autoprovisioning is enabled for a given AWS cluster. The value '1' indicates that it is enabled, while '0' indicates that it is not.\", 'dimension_descriptions': [{'cluster_autoscaler_nap_enabled': \"This dimension represents whether or not Node Autoprovisioning is enabled. Its value will be either '0' or '1'.\"}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_node_groups_count', 'chart_description': 'This chart shows the number of node groups managed by the Cluster Autoscaler (CA) in an alpha stage. Cluster Autoscaler is a tool that automatically adjusts the size of Kubernetes node groups based on the demand. This chart is useful for understanding the number of node groups that Cluster Autoscaler manages in the AWS environment.', 'dimension_descriptions': [{'cluster_autoscaler_node_groups_count': 'The total number of node groups managed by the Cluster Autoscaler in the Kubernetes cluster.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_nodes_count', 'chart_description': \"[ALPHA] Number of nodes in cluster is a line chart that displays the number of nodes currently running in the autoscaling cluster. This chart helps you monitor the number of nodes in the cluster and whether it's scaling up or down as expected. This can aid in ensuring the cluster is responsive, reliable, and responsive under different workload conditions.\", 'dimension_descriptions': [{'cluster_autoscaler_nodes_count': 'This dimension displays the number of nodes running in the Autoscaling cluster, which is a useful metric to keep an eye on when autoscaling instances are in use. This dimension helps you monitor when the cluster is scaling up or down.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_old_unregistered_nodes_removed_count', 'chart_description': '[ALPHA] Number of nodes that were unregistered by CA and were removed from the cluster due to not being able to register again. This metric helps to identify the efficiency of the cluster autoscaler and the frequency of removing old unregistered nodes. ', 'dimension_descriptions': [{'cluster_autoscaler_old_unregistered_nodes_removed_count': 'The total number of old unregistered nodes removed from the cluster by the cluster autoscaler per second.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scale_down_in_cooldown', 'chart_description': 'This chart shows whether or not the cluster autoscaler scale down is in cooldown. The value will be 1 if it is in cooldown, and 0 otherwise. This chart is part of the cluster autoscaler family and helps monitor the scaling behavior of AWS clusters.', 'dimension_descriptions': [{'cluster_autoscaler_scale_down_in_cooldown': \"This dimension tracks whether or not the scale down is in cooldown. It can provide insight into the cluster's scaling behavior and indicate whether the autoscaler is acting in accordance with the set cooldown period.\"}]}\n",
      "Error: (400, '{\"errorMsgKey\":\"ErrAllNodesFailed\",\"errorMessage\":\"ErrAllNodesFailed\",\"errorCode\":\"hQCC12HXr9-247702064\",\"nodes\":[{\"id\":\"04516a31-5287-4304-b84d-9b2a48f2b821\",\"name\":\"usecase-demo-docker-host\",\"routing_latency\":\"2.402977ms\",\"adc_latency\":\"127.731424ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"16c70a71-24d9-4d69-ae64-a0c7480aac42\",\"name\":\"usecase-demo-nginx-plus\",\"routing_latency\":\"3.294844ms\",\"adc_latency\":\"125.136254ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"19ea097c-f7df-4a2d-902e-395c867f5b28\",\"name\":\"redis-master-0\",\"routing_latency\":\"2.763794ms\",\"adc_latency\":\"8.889324ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"23eee1d8-94c0-4d25-a40a-a6bce31bc246\",\"name\":\"postgresql-0\",\"routing_latency\":\"3.460327ms\",\"adc_latency\":\"8.953235ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"2ae8c4c9-1d83-4969-8ff4-8ca533005e4c\",\"name\":\"netdata-k8s-state-8858f6cc5-tj29s\",\"routing_latency\":\"2.465318ms\",\"adc_latency\":\"5.588919ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"2d25c6fa-9064-4327-86d2-73be282fed07\",\"name\":\"netdata-collectors-0\",\"routing_latency\":\"2.481998ms\",\"adc_latency\":\"5.327054ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"45428773-5f00-457f-94a3-22a0e9e04e5f\",\"name\":\"cassandra\",\"routing_latency\":\"2.285445ms\",\"adc_latency\":\"129.132382ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"51bcb711-0280-4b02-99de-df51e0faef1c\",\"name\":\"nginx-0\",\"routing_latency\":\"3.379926ms\",\"adc_latency\":\"8.631859ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"5feb3491-6d28-4f5d-a461-6c7324366aaa\",\"name\":\"netdata-parent\",\"routing_latency\":\"2.722993ms\",\"adc_latency\":\"5.449707ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"8b6cee93-cbef-47fd-9a73-efe033cf7165\",\"name\":\"ip-10-20-137-190.ec2.internal\",\"routing_latency\":\"2.861776ms\",\"adc_latency\":\"8.765301ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"a34f80fd-fe86-4d6d-a17e-9e6714de160f\",\"name\":\"apache-0\",\"routing_latency\":\"2.853006ms\",\"adc_latency\":\"8.785761ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"ce675220-0dd0-4192-a625-8fccbdadd1f9\",\"name\":\"ip-10-20-131-242.ec2.internal\",\"routing_latency\":\"1.279305ms\",\"adc_latency\":\"3.817355ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"e288573d-5260-462f-911d-924f4bb2010c\",\"name\":\"ip-10-20-137-182.ec2.internal\",\"routing_latency\":\"4.196272ms\",\"adc_latency\":\"8.249061ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":1,\"coverage\":1,\"db_points_per_tier\":null},{\"id\":\"f30a98b9-52e5-426b-a58a-33a7bc3f0966\",\"name\":\"ip-10-20-162-81\",\"routing_latency\":\"3.308175ms\",\"adc_latency\":\"4.469217ms\",\"error\":{\"errorMsgKey\":\"ErrContextNotFound\",\"errorMessage\":\"node doesn\\'t have the requested context\",\"errorCode\":\"hQCC12HXr9-247702064\"},\"chartIDs\":[],\"hops\":0,\"coverage\":1,\"db_points_per_tier\":null}]}')\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scale_down_in_cooldown', 'chart_description': 'This chart shows whether or not the cluster autoscaler scale down is in cooldown. The value will be 1 if it is in cooldown, and 0 otherwise. This chart is part of the cluster autoscaler family and helps monitor the scaling behavior of AWS clusters.', 'dimension_descriptions': [{'cluster_autoscaler_scale_down_in_cooldown': \"This dimension tracks whether or not the scale down is in cooldown. It can provide insight into the cluster's scaling behavior and indicate whether the autoscaler is acting in accordance with the set cooldown period.\"}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_scaled_up_nodes_total', 'chart_description': 'This chart shows the number of nodes added to the AWS cluster autoscaler in a given time period. It provides insight into how the cluster is scaling and how quickly new nodes are being added.', 'dimension_descriptions': [{'cluster_autoscaler_scaled_up_nodes_total': 'The total number of nodes that have been added by the cluster autoscaler.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unneeded_nodes_count', 'chart_description': '[ALPHA] Number of nodes currently considered unneeded by Cluster Autoscaler.', 'dimension_descriptions': [{'cluster_autoscaler_unneeded_nodes_count': 'The number of nodes that are currently considered unneeded by the Cluster Autoscaler. These nodes have lower utilization compared to the other nodes in the cluster and can be terminated to save costs.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unremovable_nodes_count', 'chart_description': '[ALPHA] Number of nodes that are currently considered unremovable by Cluster Autoscaler (CA).', 'dimension_descriptions': [{'cluster_autoscaler_unremovable_nodes_count': 'The number of nodes currently considered unremovable by CA.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.cluster_autoscaler_unschedulable_pods_count', 'chart_description': 'This chart displays the number of unschedulable pods in the cluster. This can be an indicator of insufficient resources, such as CPU or memory, or scheduling issues.', 'dimension_descriptions': [{'cluster_autoscaler_unschedulable_pods_count': 'The number of unschedulable pods in the cluster, which means they cannot be assigned to any node due to various reasons, such as insufficient resources or node availability issues.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.get_token_count', 'chart_description': \"This chart tracks the number of Token() requests made to the alternate token source in Amazon's Cluster Autoscaler. It is an experimental feature currently in alpha stage.\", 'dimension_descriptions': [{'get_token_count': 'The total number of Token() requests made per second.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.get_token_fail_count', 'chart_description': 'This chart displays the count of failed Token() requests to the alternate token source in AWS cluster autoscaler.', 'dimension_descriptions': [{'get_token_fail_count': 'The count of failed Token() requests to the alternate token source.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds', 'chart_description': 'This chart shows the summary of the pause duration of garbage collection cycles in seconds for AWS cluster autoscaler running on a go programming language environment.', 'dimension_descriptions': [{'quantile_0': 'The minimum pause duration time in seconds.', 'quantile_0.25': 'The first quartile pause duration time in seconds.', 'quantile_0.5': 'The median pause duration time in seconds.', 'quantile_0.75': 'The third quartile pause duration time in seconds.', 'quantile_1': 'The maximum pause duration time in seconds.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds_count', 'chart_description': 'This chart shows the summary of the pause duration of garbage collection cycles in seconds. This is useful to monitor and optimize the GC performance of the AWS cluster autoscaler.', 'dimension_descriptions': [{'go_gc_duration_seconds_count': 'The number of GC cycles with a given pause duration.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_gc_duration_seconds_sum', 'chart_description': 'This chart shows a summary of the pause duration of garbage collection cycles taking place in the AWS cluster that is being managed by the autoscaler tool. The chart can help admins and SREs monitor the behavior of the garbage collector and identify any issues or bottlenecks.', 'dimension_descriptions': [{'go_gc_duration_seconds_sum': 'The total sum of pause duration of garbage collection cycles, which is the amount of time the application was paused in order to perform garbage collection. This metric will increase when garbage collection occurs.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_goroutines', 'chart_description': 'This chart tracks the number of goroutines currently existing in the go codebase of the AWS Cluster Autoscaler. Goroutines are lightweight threads used for concurrency in Go.', 'dimension_descriptions': [{'go_goroutines': 'This dimension shows the total number of goroutines currently running in the AWS Cluster Autoscaler codebase.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_alloc_bytes', 'chart_description': 'This chart shows the number of bytes allocated and still in use by the Go garbage collector in the AWS Cluster Autoscaler.', 'dimension_descriptions': [{'go_memstats_alloc_bytes': 'The total number of bytes allocated and still in use by the Go garbage collector.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_alloc_bytes_total', 'chart_description': \"This chart measures the total number of bytes that have been allocated, even if they have been freed in the past. It is a metric related to the Go programming language's memory usage and can indicate how much memory is being used by the cluster autoscaler in the AWS ecosystem.\", 'dimension_descriptions': [{'go_memstats_alloc_bytes_total': 'This is the dimension that tracks the total number of bytes allocated, including bytes that have been freed. It provides an overview of the total memory usage of the Go program.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_buck_hash_sys_bytes', 'chart_description': 'This chart measures the number of bytes used by the profiling bucket hash table. It helps to identify memory issues on the go layer of the AWS cluster autoscaler.', 'dimension_descriptions': [{'go_memstats_buck_hash_sys_bytes': 'The amount of memory in bytes used by the profiling bucket hash table.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_frees_total', 'chart_description': 'This chart tracks the total number of frees in the Go memory allocator of the AWS Cluster Autoscaler.', 'dimension_descriptions': [{'go_memstats_frees_total': 'The total number of frees in the Go memory allocator. This metric can be used to analyze the efficiency of the garbage collector and memory management of the application.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_gc_cpu_fraction', 'chart_description': 'This chart shows the fraction of available CPU time used by the garbage collector (GC) since the program started. It helps to monitor GC performance and ensure efficient memory management in the program.', 'dimension_descriptions': [{'go_memstats_gc_cpu_fraction': 'The fraction of CPU time used by the garbage collector. A higher value indicates that more CPU resources are being used for garbage collection, which may affect program performance.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_gc_sys_bytes', 'chart_description': 'This chart displays the number of bytes used by the Go garbage collector for system metadata in the AWS Cluster Autoscaler environment.', 'dimension_descriptions': [{'go_memstats_gc_sys_bytes': 'The number of bytes used for garbage collection system metadata by the Go memory manager.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_alloc_bytes', 'chart_description': 'This chart displays the number of heap bytes that have been allocated by the Go program and are still being used by it. It gives an idea of the amount of memory currently in use by the program.', 'dimension_descriptions': [{'go_memstats_heap_alloc_bytes': 'This dimension represents the number of heap bytes allocated and still in use by the Go program. It is a measure of the current memory usage of the program.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_idle_bytes', 'chart_description': 'This chart displays the number of heap bytes waiting to be used in the Go programming language used by the AWS Cluster Autoscaler application. This metric can help to determine if there is enough memory available for the application to function optimally.', 'dimension_descriptions': [{'go_memstats_heap_idle_bytes': 'This dimension measures the size of heap memory that is currently unused and available for allocation.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_inuse_bytes', 'chart_description': 'This chart represents the number of heap bytes that are in use by the Go program in the AWS Cluster Autoscaler.', 'dimension_descriptions': [{'go_memstats_heap_inuse_bytes': 'This dimension represents the total number of bytes allocated to the heap that are currently in use by the Go program in the AWS Cluster Autoscaler.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_objects', 'chart_description': 'Number of allocated objects chart measures the number of objects that are currently allocated in the Go heap.', 'dimension_descriptions': [{'go_memstats_heap_objects': \"The 'go_memstats_heap_objects' dimension represents the number of objects that are currently allocated in the Go heap. This metric can be used to understand heap memory usage patterns and can be helpful in optimizing memory usage in Go applications.\"}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_released_bytes', 'chart_description': \"This chart displays the number of heap bytes released to the operating system by the Go runtime. Heap memory is dynamically allocated storage in the application's virtual memory space. When the heap is freed, the memory is returned to the operating system. This chart helps track the amount of memory released by an application in order to monitor application crashes caused by memory leaks.\", 'dimension_descriptions': [{'go_memstats_heap_released_bytes': 'The amount of heap memory released to the operating system by the Go runtime, measured in bytes.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_heap_sys_bytes', 'chart_description': 'This chart displays the number of heap bytes obtained from the system by the Go memory allocator.', 'dimension_descriptions': [{'go_memstats_heap_sys_bytes': 'The amount of heap memory obtained from the operating system by the Go memory allocator in bytes. This is the total size of the heap memory segment reserved by the process virtual memory space.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_last_gc_time_seconds', 'chart_description': 'This chart displays the number of seconds since 1970 of the last garbage collection performed by the Go memory manager in the aws-cluster-autoscaler infrastructure.', 'dimension_descriptions': [{'go_memstats_last_gc_time_seconds': 'The number of seconds since 1970 of the last garbage collection. This dimension provides insight into the frequency of garbage collection performed by the Go memory manager in the aws-cluster-autoscaler infrastructure.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_lookups_total', 'chart_description': 'This chart measures the total number of pointer lookups performed by the Go memory allocator.', 'dimension_descriptions': [{'go_memstats_lookups_total': 'The total number of pointer lookups performed by the Go memory allocator. This metric can be a good indicator of memory usage because the more memory that is in use, the more pointer lookups should be performed.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_mallocs_total', 'chart_description': \"This chart measures the total number of mallocs per second performed by the Go programming language's memory allocator, as reported by the Prometheus metrics collected from the AWS cluster autoscaler.\", 'dimension_descriptions': [{'go_memstats_mallocs_total': 'The total number of mallocs that have occurred in the program since it started.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_mcache_inuse_bytes', 'chart_description': 'This chart represents the number of bytes in use by mcache structures in the Go memory allocator.', 'dimension_descriptions': [{'go_memstats_mcache_inuse_bytes': 'The number of bytes in use by mcache structures in the Go memory allocator. This metric can be helpful in identifying excessive memory usage and potential memory leaks in Go applications.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_mcache_sys_bytes', 'chart_description': 'This chart displays the number of bytes used for mcache structures obtained from the system for the AWS Cluster Autoscaler. The data is collected using Prometheus and is displayed in bytes.', 'dimension_descriptions': [{'go_memstats_mcache_sys_bytes': 'The amount of memory used by mcache structures obtained from the system. This includes the memory used by the space allocated to grow the structures.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_mcache_sys_bytes', 'chart_description': 'This chart displays the number of bytes used for mcache structures obtained from the system for the AWS Cluster Autoscaler. The data is collected using Prometheus and is displayed in bytes.', 'dimension_descriptions': [{'go_memstats_mcache_sys_bytes': 'The amount of memory used by mcache structures obtained from the system. This includes the memory used by the space allocated to grow the structures.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_mspan_sys_bytes', 'chart_description': 'This chart shows the number of bytes used for mspan structures obtained from the system in the cluster autoscaler application running on AWS.', 'dimension_descriptions': [{'go_memstats_mspan_sys_bytes': 'The size (in bytes) of the memory obtained from the system for mspan structures. Memory allocated for mspan structures is used in the garbage collection process of Go.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_next_gc_bytes', 'chart_description': 'This chart shows the number of heap bytes when the next garbage collection will take place within the go runtime environment in the AWS cluster autoscaler. Garbage collection is an automated memory management process which frees up memory space that is no longer needed by a program.', 'dimension_descriptions': [{'go_memstats_next_gc_bytes': 'The next_gc_bytes dimension represents the number of heap bytes at which the next garbage collection cycle will be triggered. It is a measure of the minimum amount of allocation required to trigger garbage collection, and can be useful in diagnosing issues related to memory allocation and usage.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_other_sys_bytes', 'chart_description': 'This chart shows the number of bytes used for other system allocations in the Go runtime memory statistics. It can provide insight into how much memory is being used for purposes other than stack or heap allocations.', 'dimension_descriptions': [{'go_memstats_other_sys_bytes': 'The amount of memory used for other system allocations in bytes.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_stack_inuse_bytes', 'chart_description': 'This chart shows the number of bytes that are currently in use by the stack allocator. The stack is where function calls and local variables reside during program execution. Monitoring this chart can help identify potential stack overflows or leaks in a Go application.', 'dimension_descriptions': [{'go_memstats_stack_inuse_bytes': 'The number of bytes currently in use by the stack. High values on this dimension may indicate that the application is allocating too much memory on the stack, which can lead to stack overflows and crashes.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_stack_sys_bytes', 'chart_description': 'This chart shows the number of bytes obtained from the system for the stack allocator in the Go language runtime used by the AWS Cluster Autoscaler. The stack allocator is responsible for managing the memory allocation for the function call stack of Go programs.', 'dimension_descriptions': [{'go_memstats_stack_sys_bytes': 'The total number of bytes obtained from the system for stack allocation. This includes the bytes returned to the kernel if stacks have shrunk.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_memstats_sys_bytes', 'chart_description': 'This chart shows the number of bytes obtained from the system by the cluster autoscaler in AWS using Prometheus monitoring. It helps in identifying the memory usage pattern of the autoscaler and optimizing it for better performance.', 'dimension_descriptions': [{'go_memstats_sys_bytes': 'The total bytes requested from the system for memory allocation by the Go runtime.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.go_threads', 'chart_description': 'This chart shows the number of OS threads created by the Autoscaler Go program in an AWS cluster. The Autoscaler is responsible for dynamically adjusting the number of nodes in a cluster based on resource usage.', 'dimension_descriptions': [{'go_threads': 'The number of OS threads created by the Autoscaler Go program. This can help identify potential performance issues or resource bottlenecks in the Autoscaler, which could affect the performance of the cluster.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_cpu_seconds_total', 'chart_description': 'This chart shows the total user and system CPU time spent in seconds for the AWS Cluster Autoscaler process. It provides insight into the amount of CPU resources utilized by the process and assists in identifying any potential performance issues or bottlenecks.', 'dimension_descriptions': [{'process_cpu_seconds_total': \"The total amount of CPU time spent in seconds by the AWS Cluster Autoscaler process. It includes both user and system CPU time and can be used to monitor the process's CPU usage over time.\"}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_max_fds', 'chart_description': 'This chart displays the maximum number of file descriptors opened by the Cluster Autoscaler process in the AWS environment. File descriptors are a key resource in Linux systems and this chart is useful for monitoring potential resource exhaustion or bottlenecks.', 'dimension_descriptions': [{'process_max_fds': 'This dimension represents the maximum number of file descriptors opened by the Cluster Autoscaler process. It is an important metric to monitor as high values may indicate potential resource exhaustion or bottleneck issues.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_open_fds', 'chart_description': 'This chart tracks the number of open file descriptors being used by the process running AWS Cluster Autoscaler. A file descriptor is a non-negative integer used to uniquely identify an open file in a process. This chart can help detect potential issues related to file descriptor exhaustion.', 'dimension_descriptions': [{'process_open_fds': 'The number of open file descriptors for the AWS Cluster Autoscaler process.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_resident_memory_bytes', 'chart_description': 'This chart displays the amount of memory in bytes that is currently being used by the AWS Cluster Autoscaler process.', 'dimension_descriptions': [{'process_resident_memory_bytes': 'This dimension refers to the resident memory size in bytes of the AWS Cluster Autoscaler process. Resident memory includes any memory held by a process that cannot be swapped out.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_start_time_seconds', 'chart_description': \"This chart shows the start time of the AWS cluster autoscaler process in seconds since the Unix epoch. The AWS Cluster Autoscaler is a tool that automatically adjusts the size of an Auto Scaling group to add or remove EC2 instances based on the group's configured scaling policies.\", 'dimension_descriptions': [{'process_start_time_seconds': 'The time at which the AWS cluster autoscaler process started, measured in seconds since the Unix epoch.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_virtual_memory_bytes', 'chart_description': 'This chart displays the virtual memory size of the process running in the AWS Cluster Autoscaler. Virtual memory size measures the total amount of memory that a process is using, including the memory it has allocated but may not be currently using.', 'dimension_descriptions': [{'process_virtual_memory_bytes': 'This dimension represents the total virtual memory size in bytes used by the process in the AWS Cluster Autoscaler.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_virtual_memory_max_bytes', 'chart_description': 'This chart shows the maximum amount of virtual memory available in bytes for the AWS Cluster Autoscaler process. Virtual memory is the total amount of memory available for use by processes and applications. This chart can be used to monitor and optimize memory usage for the autoscaler process.', 'dimension_descriptions': [{'process_virtual_memory_max_bytes': 'This dimension measures the maximum amount of virtual memory available to the AWS Cluster Autoscaler process in bytes. It is important to monitor this dimension to ensure that the process has enough memory available to operate efficiently.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.process_virtual_memory_max_bytes', 'chart_description': 'This chart shows the maximum amount of virtual memory available in bytes for the AWS Cluster Autoscaler process. Virtual memory is the total amount of memory available for use by processes and applications. This chart can be used to monitor and optimize memory usage for the autoscaler process.', 'dimension_descriptions': [{'process_virtual_memory_max_bytes': 'This dimension measures the maximum amount of virtual memory available to the AWS Cluster Autoscaler process in bytes. It is important to monitor this dimension to ensure that the process has enough memory available to operate efficiently.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_certificate_rotation_age_count', 'chart_description': '[ALPHA] Histogram of the number of seconds the last auth exec plugin client certificate lived before being rotated. If auth exec plugin client certificates are unused, histogram will contain no data', 'dimension_descriptions': [{'rest_client_exec_plugin_certificate_rotation_age_count': 'The count of certificates and the duration in seconds that they were used before being rotated.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_certificate_rotation_age_sum', 'chart_description': '[ALPHA] This chart displays a histogram of the number of seconds the last auth exec plugin client certificate lived before being rotated. If the auth exec plugin client certificates are unused, the histogram will contain no data. The dimensions of this chart help track the age of the certificates and monitor when and how frequently they are rotated. This chart can be useful for monitoring the security of your authentication processes and ensuring that client certificates are rotated frequently enough to reduce the risk of unauthorized access.', 'dimension_descriptions': [{'rest_client_exec_plugin_certificate_rotation_age_sum': 'The sum of ages (in seconds) for the last auth exec plugin client certificate before it was rotated. This dimension helps you track the age of the certificates and monitor their frequency of rotation. By comparing this dimension to other metrics, you can better understand the security of your authentication processes and identify any potential issues with certificate lifetimes.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_exec_plugin_ttl_seconds', 'chart_description': 'This chart measures the shortest Time-To-Live (TTL) of the client certificate(s) used by the auth exec plugin in seconds. The auth exec plugin provides authentication credentials to the Prometheus instance in order to pull information from the Target servers. The value is represented in seconds until the certificate expires, and is negative if the certificate has already expired. If auth exec plugins are unused or manage no TLS certificates, the value will be +INF. This chart is useful to monitor the validity of the credentials used by Prometheus to access the target servers.', 'dimension_descriptions': [{'rest_client_exec_plugin_ttl_seconds': 'The TTL of the client certificate(s) in seconds. It indicates the time remaining until the certificate(s) issued by the auth exec plugin expire. A negative value indicates the client certificate(s) have already expired. If auth exec plugins are unused or manage no TLS certificates, the value will be +INF.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds', 'chart_description': 'This chart shows the request latency in seconds for the AWS cluster autoscaler broken down by verb and URL. It is useful for identifying potential performance bottlenecks and optimizing the response time of the autoscaler.', 'dimension_descriptions': [{'bucket_+Inf': 'The number of requests that took more than 0.512 seconds to complete.', 'bucket_0.004': 'The number of requests that took between 0 and 0.004 seconds to complete.', 'bucket_0.008': 'The number of requests that took between 0.004 and 0.008 seconds to complete.', 'bucket_0.016': 'The number of requests that took between 0.008 and 0.016 seconds to complete.', 'bucket_0.032': 'The number of requests that took between 0.016 and 0.032 seconds to complete.', 'bucket_0.064': 'The number of requests that took between 0.032 and 0.064 seconds to complete.', 'bucket_0.128': 'The number of requests that took between 0.064 and 0.128 seconds to complete.', 'bucket_0.256': 'The number of requests that took between 0.128 and 0.256 seconds to complete.', 'bucket_0.512': 'The number of requests that took between 0.256 and 0.512 seconds to complete.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds_count', 'chart_description': '[ALPHA] Request latency in seconds. Broken down by verb and URL. This chart displays the duration of client requests made to the AWS cluster autoscaler REST API, categorized by HTTP verb and URL. It can be used to measure the time taken by different types of requests and identify bottlenecks in the system.', 'dimension_descriptions': [{'rest_client_request_duration_seconds_count': 'The total number of client requests made to the AWS cluster autoscaler REST API, categorized by HTTP verb and URL. This metric can be used to measure the overall load on the system and identify any sudden spikes in traffic.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_request_duration_seconds_sum', 'chart_description': 'This chart tracks the request latency in seconds for requests made to the AWS Cluster Autoscaler REST client. The latency is broken down by verb and URL.', 'dimension_descriptions': [{'rest_client_request_duration_seconds_sum': 'The sum of request durations in seconds for the specific verb and URL combination.'}]}\n",
      "{'chart_id': 'prometheus.aws-cluster-autoscaler.rest_client_requests_total', 'chart_description': 'This chart monitors the number of HTTP requests made by the rest client to the AWS cluster autoscaler, partitioned by status code, method and host.', 'dimension_descriptions': [{'rest_client_requests_total': 'The total number of HTTP requests made by the rest client, partitioned by status code, method and host.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_active_workers', 'chart_description': 'This chart displays the number of currently active workers per controller in the AWS Load Balancer Controller runtime family.', 'dimension_descriptions': [{'controller_runtime_active_workers': 'The number of active workers currently being used by the controller.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_max_concurrent_reconciles', 'chart_description': 'This chart shows the maximum number of concurrent reconciles happening per controller in the aws-load-balancer-controller runtime environment. This metric is important for understanding the workload and capacity requirements of the controllers and can help with tuning their performance.', 'dimension_descriptions': [{'controller_runtime_max_concurrent_reconciles': 'This is the only dimension in this chart, and it represents the maximum number of concurrent reconciles happening per controller. A high value for this dimension suggests that the controller workload is high and may indicate a need for more controller instances or better resource allocation.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_reconcile_errors_total', 'chart_description': 'This chart measures the total number of reconciliation errors that occurred per controller for the AWS load balancer. Reconciliation errors happen when the current state of an object in the cluster cannot be updated to match the desired state, which can be caused by various reasons such as network issues, resource constraints, or bugs in the system.', 'dimension_descriptions': [{'controller_runtime_reconcile_errors_total': 'The total number of reconciliation errors that occurred per controller.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_reconcile_total', 'chart_description': 'This chart measures the total number of reconciliations performed by the AWS Load Balancer Controller. Reconciliation typically refers to the process of ensuring that the current state of the system matches the desired state.', 'dimension_descriptions': [{'controller_runtime_reconcile_total': \"This dimension represents the total number of reconciliations performed by a controller. Each controller's number of reconciliations can be tracked separately by adding a filter to this dimension.\"}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_reconcile_total', 'chart_description': 'This chart measures the total number of reconciliations performed by the AWS Load Balancer Controller. Reconciliation typically refers to the process of ensuring that the current state of the system matches the desired state.', 'dimension_descriptions': [{'controller_runtime_reconcile_total': \"This dimension represents the total number of reconciliations performed by a controller. Each controller's number of reconciliations can be tracked separately by adding a filter to this dimension.\"}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.controller_runtime_webhook_requests_total', 'chart_description': 'This chart records the total number of admission requests by HTTP status code for the AWS load balancer controller.', 'dimension_descriptions': [{'controller_runtime_webhook_requests_total': 'The total number of admission requests made by the AWS load balancer controller, grouped by HTTP status code.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds', 'chart_description': 'This chart displays a summary of the pause duration of garbage collection cycles in seconds. It helps identify how long the garbage collection process takes and if it may be impacting latency or performance.', 'dimension_descriptions': [{'quantile_0': 'The minimum pause duration for the garbage collection process.', 'quantile_0.25': '25% of the pause duration values for garbage collection cycles fall below this value.', 'quantile_0.5': '50% of the pause duration values for garbage collection cycles fall below this value.', 'quantile_0.75': '75% of the pause duration values for garbage collection cycles fall below this value.', 'quantile_1': 'The maximum pause duration for the garbage collection process.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds_count', 'chart_description': 'This chart gives a summary of the pause duration of garbage collection cycles. Garbage collection is a process in programming where unused memory is identified and freed up for reuse. This chart can help identify any issues related to garbage collection taking too long, which can negatively impact system performance.', 'dimension_descriptions': [{'go_gc_duration_seconds_count': 'The number of garbage collection cycles and the pause duration of each cycle. This dimension can help identify if there are issues with garbage collection taking too long or happening too frequently, which can indicate a need for memory optimization and troubleshooting.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_gc_duration_seconds_sum', 'chart_description': 'This chart displays a summary of the pause duration of garbage collection (GC) cycles in seconds. Pause duration is the amount of time the Go runtime stops executing the program to perform GC.', 'dimension_descriptions': [{'go_gc_duration_seconds_sum': 'This dimension represents a cumulative sum of GC pause durations in seconds.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_goroutines', 'chart_description': 'This chart shows the number of goroutines currently active in the AWS Load Balancer Controller.', 'dimension_descriptions': [{'go_goroutines': 'The number of go routines currently active in the AWS Load Balancer Controller.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_alloc_bytes', 'chart_description': \"This chart displays the number of bytes allocated and still in use in the AWS Load Balancer Controller's Go memory statistics.\", 'dimension_descriptions': [{'go_memstats_alloc_bytes': 'The current number of bytes allocated and still in use by the Go memory allocator. This includes all memory that has been allocated but not yet freed.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_alloc_bytes_total', 'chart_description': 'This chart shows the total number of bytes allocated by the AWS Load Balancer Controller in Go programming language, including the ones that have been freed already. This chart gives an insight into the memory allocation performance of the Controller.', 'dimension_descriptions': [{'go_memstats_alloc_bytes_total': 'The total number of bytes allocated by the Controller. This metric includes all successful memory allocations, even if they have already been freed.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_buck_hash_sys_bytes', 'chart_description': 'This chart shows the number of bytes used by the profiling bucket hash table in the Go memory statistics of the AWS load balancer controller.', 'dimension_descriptions': [{'go_memstats_buck_hash_sys_bytes': 'The number of bytes used by the profiling bucket hash table in the Go memory statistics.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_frees_total', 'chart_description': 'This chart shows the total number of frees per second in the Go memory statistics for the AWS Load Balancer Controller.', 'dimension_descriptions': [{'go_memstats_frees_total': 'The total number of frees per second. This metric indicates the rate at which objects are being freed from memory.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_gc_cpu_fraction', 'chart_description': 'This chart tracks the fraction of the available CPU time utilized by the garbage collector (GC) of the AWS Load Balancer Controller Go program since its inception. The GC is an automatic memory management process that reclaims memory occupied by objects that are no longer in use.', 'dimension_descriptions': [{'go_memstats_gc_cpu_fraction': 'The fraction of CPU time used by the Garbage Collector since program start. A higher value indicates that the GC is consuming a larger portion of the CPU, potentially impacting the overall application performance.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_gc_sys_bytes', 'chart_description': 'This chart shows the number of bytes used for garbage collection system metadata in the Go runtime of the AWS load balancer controller.', 'dimension_descriptions': [{'go_memstats_gc_sys_bytes': \"The amount of memory used by the garbage collector's system-level metadata in bytes, which includes things like block descriptors, stack frames, and free list data structures.\"}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_alloc_bytes', 'chart_description': 'This chart shows the number of heap bytes that have been allocated and are still in use by the AWS load balancer controller process, as reported by the Go runtime memory statistics. This metric can help to detect and monitor memory usage of the controller.', 'dimension_descriptions': [{'go_memstats_heap_alloc_bytes': 'The amount of memory in bytes that has been allocated from the heap but has not yet been freed. This metric represents the current heap memory usage of the AWS load balancer controller process.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_idle_bytes', 'chart_description': 'This chart displays the number of heap bytes waiting to be used, indicating the amount of memory allocated but not yet used. It helps monitor the idle heap bytes and optimize memory usage in AWS load balancer controller infrastructure.', 'dimension_descriptions': [{'go_memstats_heap_idle_bytes': 'The dimension represents the number of heap bytes waiting to be used by the Go runtime.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_inuse_bytes', 'chart_description': 'This chart shows the number of heap bytes that are currently in use by the Go runtime in the AWS Load Balancer Controller service. The heap is where objects are allocated in memory, and this metric represents the amount of memory being used by the application. Monitoring this chart can help detect memory leaks and optimize memory usage in the service.', 'dimension_descriptions': [{'go_memstats_heap_inuse_bytes': 'This dimension represents the current size of the heap in bytes that is in use by the Go runtime. As objects are allocated and deallocated, this value will change to reflect the current state of the heap.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_objects', 'chart_description': 'The Number of allocated objects chart measures the number of active objects that have been allocated in the heap. It is useful for tracking heap memory usage.', 'dimension_descriptions': [{'go_memstats_heap_objects': 'This is the only dimension available for this chart. It measures the number of active objects that have been allocated in the heap.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_released_bytes', 'chart_description': 'This chart shows the number of heap bytes that have been released back to the operating system by the AWS Load Balancer Controller. It is a measure of the amount of memory that is being freed up by the program and returned to the system for other applications to use.', 'dimension_descriptions': [{'go_memstats_heap_released_bytes': 'The total number of bytes of heap memory that have been released back to the operating system. This is a cumulative value and will increase over time as more memory is freed up.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_heap_sys_bytes', 'chart_description': \"This chart shows the number of heap bytes obtained from the system, as reported by the Go runtime's memory statistics (go_memstats) for the AWS load balancer controller.\", 'dimension_descriptions': [{'go_memstats_heap_sys_bytes': 'The total amount of memory obtained from the system for the Go heap. This includes any memory that has been reserved but not yet used by the heap.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_last_gc_time_seconds', 'chart_description': 'This chart shows the number of seconds since 1970 of the last garbage collection performed by the Go garbage collector in the AWS load balancer controller.', 'dimension_descriptions': [{'go_memstats_last_gc_time_seconds': 'The time (in seconds since 1970) of the last garbage collection performed by the Go garbage collector in the AWS load balancer controller. This metric can be useful for estimating how frequently garbage collection is occurring, and for identifying any spikes or irregularities in the collection process.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_lookups_total', 'chart_description': 'This chart measures the total number of pointer lookups performed by the AWS Load Balancer Controller application written in Go programming language. It can be used to monitor application memory usage and identify potential memory optimization opportunities.', 'dimension_descriptions': [{'go_memstats_lookups_total': 'The total number of pointer lookups performed by the application since it started.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_mallocs_total', 'chart_description': 'This chart displays the total number of memory allocations performed by the AWS load balancer controller in the Go programming language.', 'dimension_descriptions': [{'go_memstats_mallocs_total': 'The total number of mallocs (memory allocations) performed by the Go runtime.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_mcache_inuse_bytes', 'chart_description': 'This chart displays the number of bytes in use by mcache structures in the AWS load balancer controller. The mcache is a cache that holds memory chunks for small objects like strings and byte arrays to reduce the overhead of memory allocation in Go programs. By monitoring this chart, we can track the memory usage of this cache structure and optimize its size accordingly.', 'dimension_descriptions': [{'go_memstats_mcache_inuse_bytes': 'The number of bytes currently in use by mcache structures. This metric can help us determine whether the current size of the mcache is appropriate for the load balancer controller performance or if it needs to be resized to improve its efficiency.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_mcache_sys_bytes', 'chart_description': 'The `prometheus.aws-load-balancer-controller.go_memstats_mcache_sys_bytes` chart displays the number of bytes used for mcache structures obtained from the system. This chart is useful for monitoring the cache efficiency of the application.', 'dimension_descriptions': [{'go_memstats_mcache_sys_bytes': 'The `go_memstats_mcache_sys_bytes` dimension indicates the number of bytes used for mcache structures obtained from the system. A higher value for this dimension indicates that the application is using more memory for cache, which can increase the cache hit rate but also increase resource consumption. This dimension can be used to optimize the cache configuration of the application.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_mspan_inuse_bytes', 'chart_description': \"This chart displays the number of bytes that are currently in use by mspan structures in the AWS load balancer controller's Golang runtime. This can be useful for monitoring the memory usage of the controller and detecting any potential memory leaks.\", 'dimension_descriptions': [{'go_memstats_mspan_inuse_bytes': 'The number of bytes currently in use by mspan structures. An mspan is a metadata structure used by the Go runtime to keep track of unused memory regions that can be freed up for future allocations. Monitoring this dimension can help identify any inefficiencies in the memory usage of the AWS load balancer controller.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_mspan_sys_bytes', 'chart_description': 'This chart shows the number of bytes used for mspan structures obtained from the system. The mspan structures are used by the garbage collector to track the size of objects in memory.', 'dimension_descriptions': [{'go_memstats_mspan_sys_bytes': 'The number of bytes used for mspan structures obtained from the system. This includes any memory used by the mspan metadata as well as the size of the memory blocks that are tracked by the mspan.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_next_gc_bytes', 'chart_description': 'This chart shows the number of heap bytes when the next garbage collection will take place in the AWS Load Balancer Controller using the Go programming language. It helps to monitor and optimize memory usage in the application.', 'dimension_descriptions': [{'go_memstats_next_gc_bytes': 'The amount of heap bytes in use before the next garbage collection will take place. This metric can be used to identify memory leaks or inefficient memory usage.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_other_sys_bytes', 'chart_description': \"This chart shows the number of bytes used for other system allocations by the aws-load-balancer-controller in the Go language. These allocations are not directly managed by Go's garbage collector and can impact overall system performance.\", 'dimension_descriptions': [{'go_memstats_other_sys_bytes': 'The amount of memory used for other system allocations by the aws-load-balancer-controller in the Go language. Higher values may indicate that the system is under heavy load and may benefit from additional resources.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_stack_inuse_bytes', 'chart_description': 'This chart measures the number of bytes in use by the stack allocator. Stack allocator is a special region of memory used to store stack frames and is created when a program is run. It is often used to store local variables, function arguments, and pointers.', 'dimension_descriptions': [{'go_memstats_stack_inuse_bytes': 'The amount of stack memory in use at the time of the measurement.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_stack_sys_bytes', 'chart_description': \"This chart shows the number of bytes obtained from the system for stack allocator in AWS load balancer controller's Go language runtime.\", 'dimension_descriptions': [{'go_memstats_stack_sys_bytes': 'Amount of memory obtained from the system for stack allocation.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_memstats_sys_bytes', 'chart_description': 'This chart shows the amount of memory obtained from the system by the aws-load-balancer-controller using the Go programming language.', 'dimension_descriptions': [{'go_memstats_sys_bytes': 'The size of the memory obtained from the system by the aws-load-balancer-controller in bytes. This includes both the virtual and physical memory.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.go_threads', 'chart_description': 'This chart shows the number of operating system (OS) threads created by the Go runtime used by the AWS Load Balancer Controller. The number of threads can impact the performance of the controller.', 'dimension_descriptions': [{'go_threads': 'The number of OS threads created by the Go runtime used by the AWS Load Balancer Controller.'}]}\n",
      "{'chart_id': 'prometheus.aws-load-balancer-controller.process_cpu_seconds_total', 'chart_description': 'This chart displays the total user and system CPU time spent by the AWS load balancer controller process, in seconds.', 'dimension_descriptions': [{'process_cpu_seconds_total': 'The cumulative CPU seconds used by the AWS load balancer controller process.'}]}\n"
     ]
    },
    {
     "ename": "APIConnectionError",
     "evalue": "Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRemoteDisconnected\u001b[0m                        Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mRemoteDisconnected\u001b[0m: Remote end closed connection without response",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mProtocolError\u001b[0m                             Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\requests\\adapters.py:489\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    488\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m chunked:\n\u001b[1;32m--> 489\u001b[0m     resp \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49murlopen(\n\u001b[0;32m    490\u001b[0m         method\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mmethod,\n\u001b[0;32m    491\u001b[0m         url\u001b[39m=\u001b[39;49murl,\n\u001b[0;32m    492\u001b[0m         body\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mbody,\n\u001b[0;32m    493\u001b[0m         headers\u001b[39m=\u001b[39;49mrequest\u001b[39m.\u001b[39;49mheaders,\n\u001b[0;32m    494\u001b[0m         redirect\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    495\u001b[0m         assert_same_host\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    496\u001b[0m         preload_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    497\u001b[0m         decode_content\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m,\n\u001b[0;32m    498\u001b[0m         retries\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmax_retries,\n\u001b[0;32m    499\u001b[0m         timeout\u001b[39m=\u001b[39;49mtimeout,\n\u001b[0;32m    500\u001b[0m     )\n\u001b[0;32m    502\u001b[0m \u001b[39m# Send the request.\u001b[39;00m\n\u001b[0;32m    503\u001b[0m \u001b[39melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:787\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    785\u001b[0m     e \u001b[39m=\u001b[39m ProtocolError(\u001b[39m\"\u001b[39m\u001b[39mConnection aborted.\u001b[39m\u001b[39m\"\u001b[39m, e)\n\u001b[1;32m--> 787\u001b[0m retries \u001b[39m=\u001b[39m retries\u001b[39m.\u001b[39;49mincrement(\n\u001b[0;32m    788\u001b[0m     method, url, error\u001b[39m=\u001b[39;49me, _pool\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m, _stacktrace\u001b[39m=\u001b[39;49msys\u001b[39m.\u001b[39;49mexc_info()[\u001b[39m2\u001b[39;49m]\n\u001b[0;32m    789\u001b[0m )\n\u001b[0;32m    790\u001b[0m retries\u001b[39m.\u001b[39msleep()\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\util\\retry.py:550\u001b[0m, in \u001b[0;36mRetry.increment\u001b[1;34m(self, method, url, response, error, _pool, _stacktrace)\u001b[0m\n\u001b[0;32m    549\u001b[0m \u001b[39mif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mFalse\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_is_method_retryable(method):\n\u001b[1;32m--> 550\u001b[0m     \u001b[39mraise\u001b[39;00m six\u001b[39m.\u001b[39;49mreraise(\u001b[39mtype\u001b[39;49m(error), error, _stacktrace)\n\u001b[0;32m    551\u001b[0m \u001b[39melif\u001b[39;00m read \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\packages\\six.py:769\u001b[0m, in \u001b[0;36mreraise\u001b[1;34m(tp, value, tb)\u001b[0m\n\u001b[0;32m    768\u001b[0m \u001b[39mif\u001b[39;00m value\u001b[39m.\u001b[39m__traceback__ \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m tb:\n\u001b[1;32m--> 769\u001b[0m     \u001b[39mraise\u001b[39;00m value\u001b[39m.\u001b[39mwith_traceback(tb)\n\u001b[0;32m    770\u001b[0m \u001b[39mraise\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:703\u001b[0m, in \u001b[0;36mHTTPConnectionPool.urlopen\u001b[1;34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, **response_kw)\u001b[0m\n\u001b[0;32m    702\u001b[0m \u001b[39m# Make the request on the httplib connection object.\u001b[39;00m\n\u001b[1;32m--> 703\u001b[0m httplib_response \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_make_request(\n\u001b[0;32m    704\u001b[0m     conn,\n\u001b[0;32m    705\u001b[0m     method,\n\u001b[0;32m    706\u001b[0m     url,\n\u001b[0;32m    707\u001b[0m     timeout\u001b[39m=\u001b[39;49mtimeout_obj,\n\u001b[0;32m    708\u001b[0m     body\u001b[39m=\u001b[39;49mbody,\n\u001b[0;32m    709\u001b[0m     headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    710\u001b[0m     chunked\u001b[39m=\u001b[39;49mchunked,\n\u001b[0;32m    711\u001b[0m )\n\u001b[0;32m    713\u001b[0m \u001b[39m# If we're going to release the connection in ``finally:``, then\u001b[39;00m\n\u001b[0;32m    714\u001b[0m \u001b[39m# the response doesn't need to know about the connection. Otherwise\u001b[39;00m\n\u001b[0;32m    715\u001b[0m \u001b[39m# it will also try to release it and we'll have a double-release\u001b[39;00m\n\u001b[0;32m    716\u001b[0m \u001b[39m# mess.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:449\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    445\u001b[0m         \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m             \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m             \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m             \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n\u001b[1;32m--> 449\u001b[0m             six\u001b[39m.\u001b[39;49mraise_from(e, \u001b[39mNone\u001b[39;49;00m)\n\u001b[0;32m    450\u001b[0m \u001b[39mexcept\u001b[39;00m (SocketTimeout, BaseSSLError, SocketError) \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32m<string>:3\u001b[0m, in \u001b[0;36mraise_from\u001b[1;34m(value, from_value)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\urllib3\\connectionpool.py:444\u001b[0m, in \u001b[0;36mHTTPConnectionPool._make_request\u001b[1;34m(self, conn, method, url, timeout, chunked, **httplib_request_kw)\u001b[0m\n\u001b[0;32m    443\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 444\u001b[0m     httplib_response \u001b[39m=\u001b[39m conn\u001b[39m.\u001b[39;49mgetresponse()\n\u001b[0;32m    445\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mBaseException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m    446\u001b[0m     \u001b[39m# Remove the TypeError from the exception chain in\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     \u001b[39m# Python 3 (including for exceptions like SystemExit).\u001b[39;00m\n\u001b[0;32m    448\u001b[0m     \u001b[39m# Otherwise it looks like a bug in the code.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:1374\u001b[0m, in \u001b[0;36mHTTPConnection.getresponse\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1373\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1374\u001b[0m     response\u001b[39m.\u001b[39;49mbegin()\n\u001b[0;32m   1375\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:318\u001b[0m, in \u001b[0;36mHTTPResponse.begin\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    317\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[1;32m--> 318\u001b[0m     version, status, reason \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_read_status()\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m status \u001b[39m!=\u001b[39m CONTINUE:\n",
      "File \u001b[1;32mC:\\Python310\\lib\\http\\client.py:287\u001b[0m, in \u001b[0;36mHTTPResponse._read_status\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    284\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m line:\n\u001b[0;32m    285\u001b[0m     \u001b[39m# Presumably, the server closed the connection before\u001b[39;00m\n\u001b[0;32m    286\u001b[0m     \u001b[39m# sending a valid response.\u001b[39;00m\n\u001b[1;32m--> 287\u001b[0m     \u001b[39mraise\u001b[39;00m RemoteDisconnected(\u001b[39m\"\u001b[39m\u001b[39mRemote end closed connection without\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[0;32m    288\u001b[0m                              \u001b[39m\"\u001b[39m\u001b[39m response\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    289\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
      "\u001b[1;31mProtocolError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mConnectionError\u001b[0m                           Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\openai\\api_requestor.py:516\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    515\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 516\u001b[0m     result \u001b[39m=\u001b[39m _thread_context\u001b[39m.\u001b[39;49msession\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    517\u001b[0m         method,\n\u001b[0;32m    518\u001b[0m         abs_url,\n\u001b[0;32m    519\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    520\u001b[0m         data\u001b[39m=\u001b[39;49mdata,\n\u001b[0;32m    521\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    522\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    523\u001b[0m         timeout\u001b[39m=\u001b[39;49mrequest_timeout \u001b[39mif\u001b[39;49;00m request_timeout \u001b[39melse\u001b[39;49;00m TIMEOUT_SECS,\n\u001b[0;32m    524\u001b[0m     )\n\u001b[0;32m    525\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mTimeout \u001b[39mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\requests\\sessions.py:587\u001b[0m, in \u001b[0;36mSession.request\u001b[1;34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[0m\n\u001b[0;32m    586\u001b[0m send_kwargs\u001b[39m.\u001b[39mupdate(settings)\n\u001b[1;32m--> 587\u001b[0m resp \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msend(prep, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39msend_kwargs)\n\u001b[0;32m    589\u001b[0m \u001b[39mreturn\u001b[39;00m resp\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\requests\\sessions.py:701\u001b[0m, in \u001b[0;36mSession.send\u001b[1;34m(self, request, **kwargs)\u001b[0m\n\u001b[0;32m    700\u001b[0m \u001b[39m# Send the request\u001b[39;00m\n\u001b[1;32m--> 701\u001b[0m r \u001b[39m=\u001b[39m adapter\u001b[39m.\u001b[39msend(request, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m    703\u001b[0m \u001b[39m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\requests\\adapters.py:547\u001b[0m, in \u001b[0;36mHTTPAdapter.send\u001b[1;34m(self, request, stream, timeout, verify, cert, proxies)\u001b[0m\n\u001b[0;32m    546\u001b[0m \u001b[39mexcept\u001b[39;00m (ProtocolError, \u001b[39mOSError\u001b[39;00m) \u001b[39mas\u001b[39;00m err:\n\u001b[1;32m--> 547\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mConnectionError\u001b[39;00m(err, request\u001b[39m=\u001b[39mrequest)\n\u001b[0;32m    549\u001b[0m \u001b[39mexcept\u001b[39;00m MaxRetryError \u001b[39mas\u001b[39;00m e:\n",
      "\u001b[1;31mConnectionError\u001b[0m: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[240], line 38\u001b[0m\n\u001b[0;32m     33\u001b[0m messages\u001b[39m=\u001b[39m[\n\u001b[0;32m     34\u001b[0m     {\u001b[39m\"\u001b[39m\u001b[39mrole\u001b[39m\u001b[39m\"\u001b[39m: \u001b[39m\"\u001b[39m\u001b[39muser\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mcontent\u001b[39m\u001b[39m\"\u001b[39m: prompt}\n\u001b[0;32m     35\u001b[0m ]\n\u001b[0;32m     37\u001b[0m \u001b[39m# call openai api\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m completion \u001b[39m=\u001b[39m openai\u001b[39m.\u001b[39;49mChatCompletion\u001b[39m.\u001b[39;49mcreate(\n\u001b[0;32m     39\u001b[0m model\u001b[39m=\u001b[39;49m\u001b[39m\"\u001b[39;49m\u001b[39mgpt-3.5-turbo\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m     40\u001b[0m messages\u001b[39m=\u001b[39;49mmessages,\n\u001b[0;32m     41\u001b[0m )\n\u001b[0;32m     43\u001b[0m reply_content \u001b[39m=\u001b[39m completion\u001b[39m.\u001b[39mchoices[\u001b[39m0\u001b[39m]\u001b[39m.\u001b[39mmessage\u001b[39m.\u001b[39mcontent\n\u001b[0;32m     44\u001b[0m \u001b[39m#pp.pprint(reply_content)\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\openai\\api_resources\\chat_completion.py:25\u001b[0m, in \u001b[0;36mChatCompletion.create\u001b[1;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m     24\u001b[0m     \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m---> 25\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39m()\u001b[39m.\u001b[39mcreate(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m     26\u001b[0m     \u001b[39mexcept\u001b[39;00m TryAgain \u001b[39mas\u001b[39;00m e:\n\u001b[0;32m     27\u001b[0m         \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m time\u001b[39m.\u001b[39mtime() \u001b[39m>\u001b[39m start \u001b[39m+\u001b[39m timeout:\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\openai\\api_resources\\abstract\\engine_api_resource.py:153\u001b[0m, in \u001b[0;36mEngineAPIResource.create\u001b[1;34m(cls, api_key, api_base, api_type, request_id, api_version, organization, **params)\u001b[0m\n\u001b[0;32m    127\u001b[0m \u001b[39m@classmethod\u001b[39m\n\u001b[0;32m    128\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mcreate\u001b[39m(\n\u001b[0;32m    129\u001b[0m     \u001b[39mcls\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams,\n\u001b[0;32m    137\u001b[0m ):\n\u001b[0;32m    138\u001b[0m     (\n\u001b[0;32m    139\u001b[0m         deployment_id,\n\u001b[0;32m    140\u001b[0m         engine,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    150\u001b[0m         api_key, api_base, api_type, api_version, organization, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mparams\n\u001b[0;32m    151\u001b[0m     )\n\u001b[1;32m--> 153\u001b[0m     response, _, api_key \u001b[39m=\u001b[39m requestor\u001b[39m.\u001b[39;49mrequest(\n\u001b[0;32m    154\u001b[0m         \u001b[39m\"\u001b[39;49m\u001b[39mpost\u001b[39;49m\u001b[39m\"\u001b[39;49m,\n\u001b[0;32m    155\u001b[0m         url,\n\u001b[0;32m    156\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    157\u001b[0m         headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    158\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    159\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    160\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    161\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[39mif\u001b[39;00m stream:\n\u001b[0;32m    164\u001b[0m         \u001b[39m# must be an iterator\u001b[39;00m\n\u001b[0;32m    165\u001b[0m         \u001b[39massert\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(response, OpenAIResponse)\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\openai\\api_requestor.py:216\u001b[0m, in \u001b[0;36mAPIRequestor.request\u001b[1;34m(self, method, url, params, headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    205\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrequest\u001b[39m(\n\u001b[0;32m    206\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[0;32m    207\u001b[0m     method,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    214\u001b[0m     request_timeout: Optional[Union[\u001b[39mfloat\u001b[39m, Tuple[\u001b[39mfloat\u001b[39m, \u001b[39mfloat\u001b[39m]]] \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m,\n\u001b[0;32m    215\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tuple[Union[OpenAIResponse, Iterator[OpenAIResponse]], \u001b[39mbool\u001b[39m, \u001b[39mstr\u001b[39m]:\n\u001b[1;32m--> 216\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrequest_raw(\n\u001b[0;32m    217\u001b[0m         method\u001b[39m.\u001b[39;49mlower(),\n\u001b[0;32m    218\u001b[0m         url,\n\u001b[0;32m    219\u001b[0m         params\u001b[39m=\u001b[39;49mparams,\n\u001b[0;32m    220\u001b[0m         supplied_headers\u001b[39m=\u001b[39;49mheaders,\n\u001b[0;32m    221\u001b[0m         files\u001b[39m=\u001b[39;49mfiles,\n\u001b[0;32m    222\u001b[0m         stream\u001b[39m=\u001b[39;49mstream,\n\u001b[0;32m    223\u001b[0m         request_id\u001b[39m=\u001b[39;49mrequest_id,\n\u001b[0;32m    224\u001b[0m         request_timeout\u001b[39m=\u001b[39;49mrequest_timeout,\n\u001b[0;32m    225\u001b[0m     )\n\u001b[0;32m    226\u001b[0m     resp, got_stream \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_interpret_response(result, stream)\n\u001b[0;32m    227\u001b[0m     \u001b[39mreturn\u001b[39;00m resp, got_stream, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapi_key\n",
      "File \u001b[1;32mc:\\Users\\andre\\Documents\\repos\\netdata-gpt-notebooks\\venv\\lib\\site-packages\\openai\\api_requestor.py:528\u001b[0m, in \u001b[0;36mAPIRequestor.request_raw\u001b[1;34m(self, method, url, params, supplied_headers, files, stream, request_id, request_timeout)\u001b[0m\n\u001b[0;32m    526\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mTimeout(\u001b[39m\"\u001b[39m\u001b[39mRequest timed out: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    527\u001b[0m \u001b[39mexcept\u001b[39;00m requests\u001b[39m.\u001b[39mexceptions\u001b[39m.\u001b[39mRequestException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m--> 528\u001b[0m     \u001b[39mraise\u001b[39;00m error\u001b[39m.\u001b[39mAPIConnectionError(\n\u001b[0;32m    529\u001b[0m         \u001b[39m\"\u001b[39m\u001b[39mError communicating with OpenAI: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(e)\n\u001b[0;32m    530\u001b[0m     ) \u001b[39mfrom\u001b[39;00m \u001b[39me\u001b[39;00m\n\u001b[0;32m    531\u001b[0m util\u001b[39m.\u001b[39mlog_debug(\n\u001b[0;32m    532\u001b[0m     \u001b[39m\"\u001b[39m\u001b[39mOpenAI API response\u001b[39m\u001b[39m\"\u001b[39m,\n\u001b[0;32m    533\u001b[0m     path\u001b[39m=\u001b[39mabs_url,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    536\u001b[0m     request_id\u001b[39m=\u001b[39mresult\u001b[39m.\u001b[39mheaders\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mX-Request-Id\u001b[39m\u001b[39m\"\u001b[39m),\n\u001b[0;32m    537\u001b[0m )\n\u001b[0;32m    538\u001b[0m \u001b[39m# Don't read the whole stream for debug logging unless necessary.\u001b[39;00m\n",
      "\u001b[1;31mAPIConnectionError\u001b[0m: Error communicating with OpenAI: ('Connection aborted.', RemoteDisconnected('Remote end closed connection without response'))"
     ]
    }
   ],
   "source": [
    "if not os.path.exists(output_dir):\n",
    "   os.makedirs(output_dir)\n",
    "\n",
    "for chart in charts_list:\n",
    "    \n",
    "    #print(chart)\n",
    "    \n",
    "    try:\n",
    "        df = get_data_cloud(space_id, room_id, chart)\n",
    "    except:\n",
    "        next\n",
    "    #print(df.shape)\n",
    "    #print(df.head())\n",
    "\n",
    "    dimensions = df.columns\n",
    "    #print(dimensions)\n",
    "    \n",
    "    chart_json = {}\n",
    "    chart_json['id'] = chart\n",
    "    chart_json['title'] = charts[chart]['title']\n",
    "    chart_json['dimensions'] = list(dimensions)\n",
    "    chart_json['units'] = charts[chart]['units']\n",
    "    chart_json['family'] = charts[chart]['family']\n",
    "    chart_json['context'] = charts[chart]['context']\n",
    "    chart_json['chart_type'] = charts[chart]['chartType']\n",
    "    chart_json['chart_labels'] = charts[chart]['chartLabels']\n",
    "    \n",
    "    prompt = make_prompt(chart, chart_json)\n",
    "    \n",
    "    #print(prompt)\n",
    "    \n",
    "    # build messages list to pass to openai\n",
    "    messages=[\n",
    "        {\"role\": \"user\", \"content\": prompt}\n",
    "    ]\n",
    "    \n",
    "    # call openai api\n",
    "    completion = openai.ChatCompletion.create(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    messages=messages,\n",
    "    )\n",
    "    \n",
    "    reply_content = completion.choices[0].message.content\n",
    "    #pp.pprint(reply_content)\n",
    "    reply_content = reply_content.replace('\",\\n        }]','\"\\n        }]').replace('\",\\n        }\\n    ]','\"\\n        }\\n    ]')\n",
    "    #print(reply_content)\n",
    "    \n",
    "    try:\n",
    "        chart_description_json = json.loads(reply_content)\n",
    "    except:\n",
    "        next\n",
    "    print(chart_description_json)\n",
    "    \n",
    "    file_name_prompt = f'{chart}__{now}_PROMPT.txt'\n",
    "    with open(f'{output_dir}/{file_name_prompt}', 'w') as f:\n",
    "        f.write(prompt)\n",
    "        \n",
    "    file_name_result = f'{chart}__{now}_RESULT.json'\n",
    "    with open(f'{output_dir}/{file_name_result}', 'w') as f:\n",
    "        json.dump(chart_description_json, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
